{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smreynolds92/Great-Learning/blob/main/milestone1_learner_notebook1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1: Advertising"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dGN4wbqjUIb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Context:**\n",
        "\n",
        "Retail company, \"Fashion Haven,\" operates multiple stores in different cities. The company invests in advertising campaigns to promote its latest collections through various media sources like TV, Newspaper, and Radio. They want to understand the impact of each media source on their sales revenue to optimize their advertising strategy and improve overall business performance.\n",
        "\n",
        "Currently, Fashion Haven lacks an effective method to predict the sales revenue generated from their advertising efforts accurately. As a result, they struggle to allocate their advertising budget optimally across different media channels, leading to sub optimal returns on investment and inefficient resource allocation.\n",
        "\n",
        "To address this business problem, Fashion Haven has collected historical data containing information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue across their different store locations. The goal is to build a robust predictive model that accurately estimates the sales revenue based on the media sources' advertising budgets, helping the company make data-driven decisions and drive business growth.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8k4mGiebUIb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Description:\n",
        "\n",
        "The data contains the different attributes of the advertising business. The detailed data dictionary is given below.\n",
        "\n",
        "* TV: Expenditure on media resource- TV\n",
        "* Radio: Expenditure on media resource- Radio\n",
        "* NewsPaper: Expenditure on media resource- Newspaper\n",
        "* Sales: Target Column - Amount of Sales"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "fin91pSEUIb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** I have used the class workbooks, my previous projects, and internet searches as an example for much of my coding in this project."
      ],
      "metadata": {
        "id": "quwVsarum5nJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the dataset on Blob Storage as Data Asset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "TW9ByYkLUIb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731258819238
        },
        "id": "Da6wyywjOV4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip show azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731258820508
        },
        "id": "V3flSyM3OV4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731258821543
        },
        "id": "4XfcU1vYOV4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "oymzBixSmVNY",
        "gather": {
          "logged": 1731258824875
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"4f8c6956-21ba-4424-aa60-2705417ce538\", #Provide your subscription ID as shown in the above screenshot\n",
        "    resource_group_name=\"test-resource\", #Provide your Resource Group as shown in the above screenshot\n",
        "    workspace_name=\"demo-azureml\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "GlXX_7mmmVIj",
        "gather": {
          "logged": 1731258827393
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Using the subscription_id, resource_group_name, and workspace_name from this Azure session/setup."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Z7h21RUWOV4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"mls-oct24-cluster\"\n",
        "\n",
        "try:\n",
        "    # Checking to see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # If not already created, creating the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_D2_V3\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=1,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=600,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Passing the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named mls-oct24-cluster, we'll reuse it as is.\nAMLCompute with name mls-oct24-cluster is created, the compute size is STANDARD_D2_V3\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "blEtYgHHmVDx",
        "gather": {
          "logged": 1731258829744
        },
        "outputId": "88d0fe4b-06c6-44d3-fae1-62fb8fae19a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The compute cluster is created and has a STANDARD_D2_V3 size."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "B1Dcax1MOV4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a processing script to perform the data preprocessing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "zQOAY7zzUIb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "import os\n",
        "\n",
        "## Set the name of the directory we want to create\n",
        "src_dir = \"./src\"\n",
        "\n",
        "# # The os.makedirs() function creates a directory\n",
        "# exist_ok=True means that the function will not raise an exception if the directory already exists\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "euprTo7Bto_j",
        "gather": {
          "logged": 1731258833199
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating a folder for the .py files in this notebook."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "f0gNFSN_OV4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/pre_process.py\n",
        "\n",
        "# Import the necessary modules\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import azureml.core\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.core import Workspace\n",
        "\n",
        "def main():\n",
        " \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        " # input and output arguments\n",
        " parser = argparse.ArgumentParser()\n",
        " parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        " parser.add_argument(\"--output\", type=str, help=\"path to output data\")\n",
        " args = parser.parse_args()\n",
        "\n",
        " # Start Logging\n",
        " mlflow.start_run()\n",
        "\n",
        " ###################\n",
        " #<prepare the data>\n",
        " ###################\n",
        "\n",
        " print(\"input data:\", args.data)\n",
        "\n",
        " data = pd.read_csv(args.data)\n",
        "\n",
        " ###################\n",
        " #<processing>\n",
        " ###################\n",
        "\n",
        " # Collecting the numerical features\n",
        " numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        " # Apply data scaling to numerical columns\n",
        " scaler = StandardScaler()\n",
        " data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        " # Exporting processed data to local\n",
        " processed_data_path = os.path.join(args.output, 'advertising_sales_processed.csv')\n",
        " data.to_csv(processed_data_path, index=False)\n",
        "\n",
        " # Stop Logging\n",
        " mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        " main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/pre_process.py\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "j3sFGGvxtzng",
        "gather": {
          "logged": 1731251848128
        },
        "outputId": "7f6d5a58-dc39-4e59-9bbd-3da0d155f1ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The pre-process.py file is created and stored in the ./src folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "PLH9t2tIOV4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the processing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "thK-nZljUIb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "# Define a new AML job using the `command` function\n",
        "job = command(\n",
        " inputs=dict(\n",
        " data=Input(\n",
        " type=\"uri_file\",\n",
        " path=\"./Data/Advertising_Sales.csv\",\n",
        " ),\n",
        " ),\n",
        " outputs=dict(\n",
        " output=Output(\n",
        " type=\"uri_folder\",\n",
        " # Creating the path with name for this processing job\n",
        " path=\"azureml://datastores/workspaceblobstore/paths/advertising_sales_processed_data\",\n",
        " ),\n",
        " ),\n",
        " code=\"src/\", # Location of the source code\n",
        " command=\"python pre_process.py --data ${{inputs.data}} --output ${{outputs.output}}\",\n",
        " # Specify the environment to be used for the job\n",
        " environment=\"mls-oct24-env@latest\",\n",
        " # Specify the compute target to be used for the job\n",
        " compute=\"mls-oct24-cluster\",\n",
        " # Specify the display name\n",
        " display_name=\"advertising_sales_processing\",\n",
        " # Specify the experiment name\n",
        " experiment_name=\"advertising_sales_price_processing\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Yhj39syptPUh",
        "gather": {
          "logged": 1731258840586
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The processing job is configured with parameters for this workbook/milestone."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "tyX5d7IgOV4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the processing job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "NH9Wyu63UIb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the processing job\n",
        "ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'hungry_jewel_4rnydqkgnl', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'mls-oct24-cluster', 'ContentSnapshotId': 'a3b30632-f187-4b4b-b66b-e589201e22df'}, 'print_as_yaml': False, 'id': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/jobs/hungry_jewel_4rnydqkgnl', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa39534b8b0>, 'serialize': <msrest.serialization.Serializer object at 0x7fa39534b7f0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'advertising_sales_processing', 'experiment_name': 'advertising_sales_price_processing', 'compute': 'mls-oct24-cluster', 'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/hungry_jewel_4rnydqkgnl?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/Advertising_Sales.csv', 'mode': 'ro_mount'}}, 'job_outputs': {'output': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_processed_data', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.hungry_jewel_4rnydqkgnl', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fa39534b730>}, 'outputs': {'output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fa39534b2b0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fa395349ae0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'hungry_jewel_4rnydqkgnl', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa39534b8b0>, 'serialize': <msrest.serialization.Serializer object at 0x7fa39534b700>, 'command': 'python pre_process.py --data ${{inputs.data}} --output ${{outputs.output}}', 'code': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/codes/b32df3b2-f672-47f3-ae46-f4d41c0fcaca/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/environments/mls-oct24-env/versions/2', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'advertising_sales_processing', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/Advertising_Sales.csv', 'mode': 'ro_mount'}}, 'outputs': {'output': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_processed_data', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.hungry_jewel_4rnydqkgnl', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/hungry_jewel_4rnydqkgnl?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa39534b8b0>}, 'instance_id': 'a04e67a6-ac28-4e98-a35d-cc678596a56a', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'mls-oct24-env:2', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>advertising_sales_price_processing</td><td>hungry_jewel_4rnydqkgnl</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/hungry_jewel_4rnydqkgnl?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&amp;tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "z_N_a7potUBr",
        "gather": {
          "logged": 1731258848181
        },
        "outputId": "952674c5-2e8a-4263-cf6a-a33942bcd690"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The processing job is run and a link to the jobs is also created.  The job did complete, but there are some notes for your information/warnings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "jnjS_TviOV4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a training script to perform the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "2lKLrNQ7UIb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "import os\n",
        "\n",
        "## Set the name of the directory we want to create\n",
        "src_dir = \"./src\"\n",
        "\n",
        "# # The os.makedirs() function creates a directory\n",
        "# exist_ok=True means that the function will not raise an exception if the directory already exists\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "zo96DRe3UIb7",
        "gather": {
          "logged": 1731259311288
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating a folder for the .py files in this notebook.  Although this was created earlier, I am putting another instance here just in case it is needed, if that part of the notebook was not run first."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "KLBBfcRqOV4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/main.py\n",
        "\n",
        "# Import the necessary modules\n",
        "import mlflow\n",
        "import argparse\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "mlflow.start_run()\n",
        "\n",
        "# Create an argument parser to take input arguments from command line\n",
        "def main():\n",
        "\n",
        " parser = argparse.ArgumentParser()\n",
        " parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
        " parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        " parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "\n",
        " args = parser.parse_args()\n",
        "\n",
        "\n",
        " # Load input data\n",
        " df = pd.read_csv(args.data)\n",
        "\n",
        " # Defining the variables\n",
        " target = 'Sales'\n",
        " numeric_features = ['TV','Radio', 'Newspaper']\n",
        " categorical_features = []\n",
        "\n",
        " # Creating X and y from the variables\n",
        " X = df.drop([target], axis=1)\n",
        " y = df[target]\n",
        "\n",
        " # Splitting the train and test data\n",
        " X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.2, random_state=42\n",
        " )\n",
        "\n",
        " # Defining the GradientBoostingRegressor model\n",
        " model_gbr = GradientBoostingRegressor(\n",
        " n_estimators=args.n_estimators,\n",
        " learning_rate=args.learning_rate\n",
        " )\n",
        "\n",
        " # Initialize and train a GradientBoostingRegressor model\n",
        " model_pipeline = make_pipeline(model_gbr)\n",
        " model_pipeline.fit(X_train, y_train)\n",
        "\n",
        " # Compute and log model RSquared results\n",
        " rsq = model_pipeline.score(X_test, y_test)\n",
        " mlflow.log_metric(\"RSquared\", float(rsq))\n",
        "\n",
        " # Registering the model to the workspace\n",
        " print(\"Registering model pipeline\")\n",
        " mlflow.sklearn.log_model(\n",
        " sk_model=model_pipeline,\n",
        " # Setting the name for the registered_model\n",
        " registered_model_name=\"advertising-sales-price-predictor\",\n",
        " # Setting the name for the artifact_path\n",
        " artifact_path=\"advertising-sales-price-predictor\"\n",
        " )\n",
        "\n",
        " # End of MLflow tracking\n",
        " mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        " main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/main.py\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731215698532
        },
        "id": "ywpIIT-lOV4n",
        "outputId": "079ec3a4-19c1-47b4-a376-32951ae0944e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The main.py file is created and stored in the ./src folder.  The model that is chosen is the GradientBoostingRegressor which is good for predictive problems.  The primary metric chosen is RSquared, which will measures how well a statistical model predicts an outcome."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "I4j_xWiEOV4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8onEkLZXUIb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "# Define a new AML job using the `command` function\n",
        "job = command(\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_file\", path=\"./Data/Advertising_Sales.csv\"),\n",
        "        \"n_estimators\": 100,\n",
        "        \"learning_rate\": 0.1\n",
        "    },\n",
        "    code=\"src/main.py\", # Location of the source code\n",
        "    command=\"python main.py --data ${{inputs.data}}\",\n",
        "    # Specify the environment to be used for the job\n",
        "    environment=\"mls-oct24-env@latest\",\n",
        "    # Specify the compute target to be used for the job\n",
        "    compute=\"mls-oct24-cluster\",\n",
        "    # Specify the display name\n",
        "    display_name=\"advertising_sales_training\",\n",
        "    # Specify the experiment name\n",
        "    experiment_name=\"advertising_sales_price_training\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731259318189
        },
        "id": "Deov8ZV6OV4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The training job is configured with parameters for this workbook/milestone."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "qrcHUmADOV4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the training job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "M3S1Csp7UIb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.create_or_update will create a new job if it does not exist or update the existing job if it does\n",
        "ml_client.create_or_update(job)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Command({'parameters': {}, 'init': False, 'name': 'icy_beach_7x462s6xvf', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'mls-oct24-cluster', 'ContentSnapshotId': '85e8f18c-aac4-486f-8895-f0de29f05767'}, 'print_as_yaml': False, 'id': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/jobs/icy_beach_7x462s6xvf', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa3951d5660>, 'serialize': <msrest.serialization.Serializer object at 0x7fa3951d5990>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <TraceLogger attr_dict (WARNING)>, 'display_name': 'advertising_sales_training', 'experiment_name': 'advertising_sales_price_training', 'compute': 'mls-oct24-cluster', 'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/icy_beach_7x462s6xvf?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/Advertising_Sales.csv', 'mode': 'ro_mount'}, 'n_estimators': '100', 'learning_rate': '0.1'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.icy_beach_7x462s6xvf', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fa3951d59f0>, 'n_estimators': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fa3951d5960>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fa3951d5930>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fa3951d56c0>}, 'component': CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'icy_beach_7x462s6xvf', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa3951d5660>, 'serialize': <msrest.serialization.Serializer object at 0x7fa3951d5630>, 'command': 'python main.py --data ${{inputs.data}}', 'code': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/codes/8ae4a2dc-9a28-4711-b540-d1d55c15cf11/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/environments/mls-oct24-env/versions/2', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'schema': None, 'type': 'command', 'display_name': 'advertising_sales_training', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/Advertising_Sales.csv', 'mode': 'ro_mount'}, 'n_estimators': {'type': 'string', 'default': '100'}, 'learning_rate': {'type': 'string', 'default': '0.1'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.icy_beach_7x462s6xvf', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/icy_beach_7x462s6xvf?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fa3951d5660>}, 'instance_id': 'c259ba78-a779-415b-bb18-c382f7d196fd', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'mls-oct24-env:2', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>advertising_sales_price_training</td><td>icy_beach_7x462s6xvf</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/icy_beach_7x462s6xvf?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml&amp;tid=f005fc57-31b6-44d5-b86c-cb24057a0d9e\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731259324888
        },
        "id": "U5BPmVtKOV4o",
        "outputId": "9649a36e-aa30-41df-ffaa-0ed21333e69b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The training job is run and a link to the jobs is also created."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "MMuCuLi9OV4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the parameter space for hyperparameter tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "gvveVlLUUIb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml.sweep import Choice\n",
        "\n",
        "# Reusing the command_job created before\n",
        "job_for_sweep = job(\n",
        "    n_estimators=Choice(values=[100, 200, 300, 400]),\n",
        "    learning_rate=Choice(values=[0.001, 0.005, 0.05, 0.1])\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "W60YbWwcq_Ro",
        "gather": {
          "logged": 1731259519433
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Setting the hyperparameters for the sweep job, trying different n_estimators and different learning_rate."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "NOcDVMgrOV4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the sweep job for tuning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "CYG2HACuUIb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute specifies the compute target where the sweep job will run.\n",
        "# sampling_algorithm specifies the search algorithm to use for hyperparameter tuning.\n",
        "# primary_metric specifies the metric to optimize during hyperparameter tuning.\n",
        "# goal specifies whether to maximize or minimize the primary metric.\n",
        "# max_total_trials specifies the maximum number of trials to run during hyperparameter tuning.\n",
        "# max_concurrent_trials specifies the maximum number of trials to run concurrently during hyperparameter tuning.\n",
        "\n",
        "sweep_job = job_for_sweep.sweep(\n",
        "    compute=\"mls-oct24-cluster\",\n",
        "    sampling_algorithm=\"bayesian\",\n",
        "    primary_metric=\"RSquared\",\n",
        "    goal=\"Maximize\",\n",
        "    max_total_trials=16,\n",
        "    max_concurrent_trials=3\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "3ACMpX77UIb8",
        "gather": {
          "logged": 1731259525587
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Configuring the sweep job for tuning.  The alogrithm chosen is bayesian, which uses statistical independence for the variables.  The primary metric chosen is RSquared, which will measures how well a statistical model predicts an outcome.  And it is going to try and run 16 trials."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_aE6GcTbOV4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the names for the sweep job\n",
        "sweep_job.experiment_name = \"advertising_sales_price_tuning\"\n",
        "sweep_job.display_name = \"advertising_sales_tuning\"\n",
        "sweep_job.description = \"Run a hyperparameter sweep job for GBR\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ogxyhy1Kq_3d",
        "gather": {
          "logged": 1731259531171
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the sweep job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "pS895jJkUIb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or update the sweep job\n",
        "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
        "\n",
        "# Stream the output and wait until the job is finished\n",
        "ml_client.jobs.stream(returned_sweep_job.name)\n",
        "\n",
        "# Refresh the latest status of the job after streaming\n",
        "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: olden_tongue_273yy7s51p\nWeb View: https://ml.azure.com/runs/olden_tongue_273yy7s51p?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2024-11-10T17:25:57.0418840Z][GENERATOR][DEBUG]Sampled 3 jobs from search space \n[2024-11-10T17:25:57.3183497Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_0' \n[2024-11-10T17:25:57.4160730Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_1' \n[2024-11-10T17:25:57.4172441Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_2' \n[2024-11-10T17:25:57.9572334Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_2' \n[2024-11-10T17:25:57.9000683Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_1' \n[2024-11-10T17:25:57.9485385Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_0' \n[2024-11-10T17:27:00.6242056Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:27:00.8217564Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_3' \n[2024-11-10T17:27:01.1280311Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_3' \n[2024-11-10T17:28:03.8707743Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:28:04.0734609Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_4' \n[2024-11-10T17:28:04.5269085Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_4' \n[2024-11-10T17:28:37.0132762Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:28:37.1817939Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_5' \n[2024-11-10T17:28:37.5443025Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_5' \n[2024-11-10T17:29:16.6554600Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:29:16.8552145Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_6' \n[2024-11-10T17:29:17.1454079Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_6' \n[2024-11-10T17:29:49.4530105Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:29:49.6251034Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_7' \n[2024-11-10T17:29:49.8703626Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_7' \n[2024-11-10T17:30:52.4854020Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:30:52.6532720Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_8' \n[2024-11-10T17:30:52.9517937Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_8' \n[2024-11-10T17:31:25.4930068Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:31:25.6786738Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_9' \n[2024-11-10T17:31:26.1918067Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_9' \n[2024-11-10T17:32:28.7684096Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:32:28.8929981Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_10' \n[2024-11-10T17:32:29.1403517Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_10' \n[2024-11-10T17:33:12.6920581Z][GENERATOR][DEBUG]Sampled 2 jobs from search space \n[2024-11-10T17:33:12.9539345Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_11' \n[2024-11-10T17:33:13.1479059Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_12' \n[2024-11-10T17:33:13.2629467Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_11' \n[2024-11-10T17:33:13.3911849Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_12' \n[2024-11-10T17:33:46.6735703Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:33:46.8176355Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_13' \n[2024-11-10T17:33:47.0675075Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_13' \n[2024-11-10T17:35:14.6930212Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:35:14.8311848Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_14' \n[2024-11-10T17:35:15.0854620Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_14' \n[2024-11-10T17:35:52.0377002Z][GENERATOR][DEBUG]Sampled 1 jobs from search space \n[2024-11-10T17:35:52.1713379Z][SCHEDULER][INFO]Scheduling job, id='olden_tongue_273yy7s51p_15' \n[2024-11-10T17:35:52.4989838Z][SCHEDULER][INFO]Successfully scheduled a job. Id='olden_tongue_273yy7s51p_15' \n[2024-11-10T17:36:22.3839492Z][GENERATOR][DEBUG]Setting all jobs generated as True, reason : Max number of jobs reached \n[2024-11-10T17:37:32.0985191Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n\nExecution Summary\n=================\nRunId: olden_tongue_273yy7s51p\nWeb View: https://ml.azure.com/runs/olden_tongue_273yy7s51p?wsid=/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/workspaces/demo-azureml\n\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "XM8ySvW2UIb8",
        "gather": {
          "logged": 1731260289187
        },
        "outputId": "40dfc3a0-01d3-40bc-c30c-4d9f86888922"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The sweep job is run and a link to the jobs is also created."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "w-D0DsU2OV4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the run that gave best modeling results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "FOJTVz8uUIb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "if returned_sweep_job.status == \"Completed\":\n",
        "\n",
        "    # Collecting the run which gave the best result\n",
        "    best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
        "\n",
        "    # Collecting the model from this run\n",
        "    model = Model(\n",
        "        # The script stores the model as \"advertising_sales_best_model\"\n",
        "        path=\"azureml://jobs/{}/outputs/artifacts/paths/advertising-sales-price-predictor/\".format(\n",
        "            best_run\n",
        "        ),\n",
        "        name=\"advertising_sales_best_model\",\n",
        "        description=\"Model created from advertising sales\",\n",
        "        type=\"custom_model\",\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\n",
        "        \"Sweep job status: {}. Please wait until it completes\".format(\n",
        "            returned_sweep_job.status\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "i88GYMKAUIb8",
        "gather": {
          "logged": 1731260323369
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Extracting the sweep run that had the best results.  The best model had RSquared: 0.98409, n_estimators: 100, and learning_rate: 0.005."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Lf2SfyJiOV4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the best model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_reaQx8qUIb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Registering the best model for the run\n",
        "registered_model = ml_client.models.create_or_update(model=model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "CrgmNA-3UIb9",
        "gather": {
          "logged": 1731260330299
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure an Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "nbpyXgx_UIb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Iqb3l0fnUIb9",
        "gather": {
          "logged": 1731260335400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required modules\n",
        "import random\n",
        "import string\n",
        "\n",
        "# Creating a unique endpoint name by including a random suffix\n",
        "\n",
        "# Defining a list of allowed characters for the endpoint suffix\n",
        "allowed_chars = string.ascii_lowercase + string.digits\n",
        "\n",
        "# Generating a random 5-character suffix for the endpoint name by choosing\n",
        "# characters randomly from the list of allowed characters\n",
        "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
        "\n",
        "# Creating the final endpoint name by concatenating a prefix string\n",
        "# with the generated suffix string\n",
        "endpoint_name = \"advertising-sales-endpoint-\" + endpoint_suffix"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "5OqFBwClXFrH",
        "gather": {
          "logged": 1731260340319
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating an endpoint name that is unique and appends a randomly chosen 5 characters at the end of the name."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "X527pi_WOV4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the endpoint name\n",
        "print(f\"Endpoint name: {endpoint_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint name: advertising-sales-endpoint-22vpm\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "MTJIIQwOXFj3",
        "gather": {
          "logged": 1731260346369
        },
        "outputId": "b527181d-8b87-4326-e3f0-1f161b8a8631"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Printing the name of the endpoint to show the unique name with the randomly chosen extra 5 characters."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "MrPsxDSFOV4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    # Name of the endpoint, should be unique within your deployment\n",
        "    description=\"An online endpoint serving an MLflow model for the advertising sales classification task\",\n",
        "    # A string describing the purpose of the endpoint\n",
        "    auth_mode=\"key\",\n",
        "    # Authentication mode to use for the endpoint (in this case, using an API key)\n",
        "    tags={\"foo\": \"bar\"},\n",
        "    # A dictionary of key-value pairs that can be used to tag the endpoint\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xTtaNN4OXFah",
        "gather": {
          "logged": 1731260356331
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Configuring the endpoint with a description, auth_mode, and tags."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "hmHg_qCXOV4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "0gzrvPs_UIb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://advertising-sales-endpoint-22vpm.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://advertising-sales-endpoint-22vpm.eastus2.inference.ml.azure.com/swagger.json', 'name': 'advertising-sales-endpoint-22vpm', 'description': 'An online endpoint serving an MLflow model for the advertising sales classification task', 'tags': {'foo': 'bar'}, 'properties': {'createdBy': 'Sarah Garrett', 'createdAt': '2024-11-10T17:39:29.719279+0000', 'lastModifiedAt': '2024-11-10T17:39:29.719279+0000', 'azureml.onlineendpointid': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourcegroups/test-resource/providers/microsoft.machinelearningservices/workspaces/demo-azureml/onlineendpoints/advertising-sales-endpoint-22vpm', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:9f5627da-e74d-4fdb-a9a3-135424c647ab:df9777b3-dc0c-4eda-9ad1-9352386e1fa8?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/onlineEndpoints/advertising-sales-endpoint-22vpm', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fa3951d7580>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fa3952e58a0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "0YhIW89qUIb9",
        "gather": {
          "logged": 1731260460000
        },
        "outputId": "d6793319-2faa-4248-e620-2acd1f325107"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating the endpoint.  Information about the endpoint creation is shown above for further details."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "E_AGnUe5OV4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a deployment script to perform model deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "MNCxX7FBUIb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {src_dir}/score.py\n",
        "\n",
        "# Import necessary libraries and modules\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "\n",
        "######################LOGGER#####################\n",
        "# Set up Azure logging\n",
        "import logging\n",
        "from logging import Logger\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "\n",
        "# Connect to Application Insights and set logging level to INFO\n",
        "application_insights_connection_string= 'InstrumentationKey=e040f1cb-4a7a-4009-87be-7861c813da51;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/'\n",
        "handler = AzureLogHandler(\n",
        "connection_string=application_insights_connection_string)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "####################################################\n",
        "\n",
        "# Define the init() function to load the MLflow model\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "    # models, this is generally \"mlflow-model\".\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"advertising-sales-price-predictor\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "\n",
        "# Define the run() function to make predictions using the loaded model\n",
        "def run(raw_data):\n",
        "    # Parse input data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data.keys():\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    serving_input = json.dumps(json_data[\"input_data\"])\n",
        "    data = infer_and_parse_json_input(serving_input, input_schema)\n",
        "    # Make predictions\n",
        "    predictions = model.predict(data)\n",
        "\n",
        "    # Log the input data and predictions to Azure\n",
        "    logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "\n",
        "    # Convert predictions to JSON format and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./src/score.py\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "MyLjNdieZnDT",
        "gather": {
          "logged": 1731216670257
        },
        "outputId": "11338139-8e8e-4bac-c129-6c9bf94172e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- The score.py file is created and stored in the ./src folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "C8Avhjf1OV4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new deployment with name \"blue\"\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    # Use the previously generated endpoint name\n",
        "    endpoint_name=endpoint_name,\n",
        "    # Use the registered model\n",
        "    model=registered_model,\n",
        "    # Use the latest environment named \"mls-oct24-env@latest\"\n",
        "    environment=\"mls-oct24-env@latest\",\n",
        "    # Use the code in the \"./src\" directory and the \"score.py\" script\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    # Use a single instance of type \"Standard_E2s_v3\"\n",
        "    instance_type=\"Standard_E2s_v3\",\n",
        "    instance_count=1,\n",
        "    # Enable Application Insights for the deployment\n",
        "    app_insights_enabled=True,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "KI4RBB3yZdkT",
        "gather": {
          "logged": 1731260479846
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating a new deployment named blue with parameters."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "2EruwqrQOV4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or update the blue_deployment\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint advertising-sales-endpoint-22vpm exists\n\u001b[32mUploading src (0.01 MBs): 100%|██████████| 5394/5394 [00:00<00:00, 57532.20it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "........................................................................."
        },
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'advertising-sales-endpoint-22vpm', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/odidp:9f5627da-e74d-4fdb-a9a3-135424c647ab:e4596965-ac91-42a7-a8cf-79b86ce0531b?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/onlineEndpoints/advertising-sales-endpoint-22vpm/deployments/blue', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute12/code/Users/scharon.garrett', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x7fa3952e4250>, 'serialize': <msrest.serialization.Serializer object at 0x7fa395227700>, 'model': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/models/advertising_sales_best_model/versions/4', 'code_configuration': {'code': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/codes/ab711ff6-954d-4e97-be4c-66219f474796/versions/1'}, 'environment': '/subscriptions/4f8c6956-21ba-4424-aa60-2705417ce538/resourceGroups/test-resource/providers/Microsoft.MachineLearningServices/workspaces/demo-azureml/environments/mls-oct24-env/versions/2', 'environment_variables': {'AML_APP_INSIGHTS_KEY': '7b5cf521-8e6f-43d2-bfc3-06d157fba8b1', 'AML_APP_INSIGHTS_ENDPOINT': 'https://dc.services.visualstudio.com/v2/track', 'AML_APP_INSIGHTS_ENABLED': 'true', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/advertising_sales_best_model/4', 'AZUREML_ENTRY_SCRIPT': 'score.py', 'AML_APP_ROOT': '/var/azureml-app/src'}, 'app_insights_enabled': True, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7fa395224f70>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7fa395226e00>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fa395227d90>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fa395225c30>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E2s_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "mq1o1wyZUIb9",
        "gather": {
          "logged": 1731260866923
        },
        "outputId": "968ef527-3bfd-46d5-b059-1b29de27bfab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Creating or updating the blue deployment.  Information about this deployment are shown above for further details."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "oJ4p9wMuOV4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the deployment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "5yFPhPorUIb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the deployment\n",
        "ml_client.online_endpoints.invoke(\n",
        "    #Name of the endpoint\n",
        "    endpoint_name=endpoint_name,\n",
        "    #Name of the specific deployment to test in an endpoint\n",
        "    deployment_name=\"blue\",\n",
        "    #File with request data for testing\n",
        "    request_file=\"sample-request-sklearn.json\",\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "'\"{\\\\\"predictions\\\\\": [7.123222905473065, 14.593084394064093, 13.71235667273795, 19.53728678525383, 12.288216842394489]}\"'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "mwh_A7-dUIb-",
        "gather": {
          "logged": 1731260881093
        },
        "outputId": "38a6fd95-39da-4ef2-867a-de1a39b38fdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Configuring the blue deployment with a sample json.  I created a json file since one has not been given yet.  These are the details of the json:\n",
        "\n",
        "{\"input_data\": {\n",
        "  \"dataframe_split\": {\n",
        "    \"columns\": [\n",
        "      \"TV\",\n",
        "      \"Radio\",\n",
        "      \"Newspaper\"\n",
        "    ],\n",
        "    \"data\": [\n",
        "      [17.8, 19.6, 23.5],\n",
        "      [112.3, 29.3, 49.6],\n",
        "      [74.7, 41.5, 35.2],\n",
        "      [206.3, 33.4, 1.8],\n",
        "      [228.7, 5.2, 18.3]\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "h67yjEmOOV4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete the Endpoint\n",
        "\n",
        "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "jTkKeqFkUIb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the endpoint\n",
        "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7fa3952e41f0>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".........."
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Ch_Xb86TUIb-",
        "gather": {
          "logged": 1731260920298
        },
        "outputId": "25d8cdd9-3d51-487d-bf62-7d194ce70eff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "- Deleting the endpoint, so that there is not a LIVE event running."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "omkaZWs3OV4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusions**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "J9srfLUcUIb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The data provided was complete and had 200 rows.  All the data was numerical, which helped with making this problem/solution more straight forward.\n",
        "- The model that is chosen is the GradientBoostingRegressor which is good for predictive problems - which we are trying to predict sales.  The primary metric chosen is RSquared, which will measure how well a statistical model predicts an outcome.  The alogrithm chosen is bayesian, which uses statistical independence for the variables.\n",
        "- The runs did take longer than the other code, and the sweep took the longest.  The sweep allowed for you to observe the findings in real time and to find trends and the best run.  I liked being able to choose the best run and use it going forward with the deployment.\n",
        "- The best model had RSquared: 0.98409, n_estimators: 100, and learning_rate: 0.005, which was used for the deployment.\n",
        "- Even though the json for this project was not provided, it was pretty simple to create one from the sample one in module 3.\n",
        "- This was a good start in learning about different types of storage and how you would be charged, and the same goes for live events."
      ],
      "metadata": {
        "id": "0J39EDOgrwX9"
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}